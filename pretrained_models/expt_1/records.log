#model_parameters
%input_size=60
%output_size=1
%hidden_size=128
%num_layers=2
%dropout=0.1
#train 0
%parameters=229505
%hidden size=128
%layers=2
%dropout=0.1
%epochs=64
%learn rate=0.0005588304734535363
%loss functional=L1Loss
%ma period=30
%final train loss=0.17578551366488804
%final sma train loss=0.17983945260860928
%final test loss=0.15880258069481962
%final sma test loss=0.1606607440945714
%grokfast active=False
%grokfast function=ema
%grokfast alpha=0.999
%grokfast window size=30
%grokfast lambda=1.0
%lr atten active=True
%lr atten endpoint=0.0001
%lr atten power=15.0
%notes=
#train 1
%parameters=229505
%hidden size=128
%layers=2
%dropout=0.1
%epochs=256
%learn rate=0.0001
%loss functional=L1Loss
%ma period=30
%final train loss=0.1627659182917623
%final sma train loss=0.1627060959507897
%final test loss=0.16002279381419338
%final sma test loss=0.15989112069671468
%grokfast active=True
%grokfast function=ma
%grokfast alpha=0.98
%grokfast window size=64
%grokfast lambda=2.0
%lr atten active=False
%lr atten endpoint=1e-07
%lr atten power=15.0
%notes=
#train 2
%parameters=229505
%hidden size=128
%layers=2
%dropout=0.1
%epochs=256
%learn rate=0.0001
%loss functional=L1Loss
%ma period=30
%final train loss=0.15393153980187294
%final sma train loss=0.15561945733290836
%final test loss=0.16206241693607595
%final sma test loss=0.1617959172111149
%grokfast active=True
%grokfast function=ma
%grokfast alpha=0.98
%grokfast window size=64
%grokfast lambda=2.0
%lr atten active=False
%lr atten endpoint=1e-07
%lr atten power=15.0
%notes=
#train 3
%parameters=229505
%hidden size=128
%layers=2
%dropout=0.1
%epochs=256
%learn rate=0.0001
%loss functional=L1Loss
%ma period=30
%final train loss=0.15458067428616798
%final sma train loss=0.15048531075651178
%final test loss=0.16310261640437815
%final sma test loss=0.16363615767900336
%grokfast active=True
%grokfast function=ma
%grokfast alpha=0.98
%grokfast window size=64
%grokfast lambda=2.0
%lr atten active=False
%lr atten endpoint=1e-07
%lr atten power=15.0
%notes=
#train 4
%parameters=229505
%hidden size=128
%layers=2
%dropout=0.1
%epochs=256
%learn rate=0.0001
%loss functional=L1Loss
%ma period=30
%final train loss=0.14353292588160127
%final sma train loss=0.14638793101765454
%final test loss=0.16540044476819593
%final sma test loss=0.16492032144189805
%grokfast active=True
%grokfast function=ma
%grokfast alpha=0.98
%grokfast window size=64
%grokfast lambda=2.0
%lr atten active=False
%lr atten endpoint=1e-07
%lr atten power=15.0
%notes=
#train 5
%parameters=229505
%hidden size=128
%layers=2
%dropout=0.1
%epochs=1024
%learn rate=0.0001
%loss functional=L1Loss
%ma period=30
%final train loss=0.12234754732587846
%final sma train loss=0.1290377982417992
%final test loss=0.16784142893414164
%final sma test loss=0.16791086802186891
%grokfast active=True
%grokfast function=ma
%grokfast alpha=0.98
%grokfast window size=64
%grokfast lambda=2.0
%lr atten active=False
%lr atten endpoint=2e-05
%lr atten power=10.0
%notes=
#train 6
%parameters=229505
%hidden size=128
%layers=2
%dropout=0.1
%epochs=4096
%learn rate=5e-05
%loss functional=L1Loss
%ma period=30
%final train loss=0.24014396204858643
%final sma train loss=0.21985333412677838
%final test loss=0.1679060847260231
%final sma test loss=0.20976458607718002
%grokfast active=True
%grokfast function=ma
%grokfast alpha=0.98
%grokfast window size=64
%grokfast lambda=5.0
%lr atten active=True
%lr atten endpoint=5e-05
%lr atten power=1.0
%notes=
